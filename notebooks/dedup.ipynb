{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elieb/git/unisim/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from datasets import load_dataset\n",
    "from perfcounters import PerfCounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "test = load_dataset(\"rotten_tomatoes\", split=\"test\")\n",
    "train_texts = [t['text'] for t in train]\n",
    "test_texts = [t['text'] for t in test]\n",
    "num_train_texts = len(train_texts)\n",
    "num_test_texts = len(test_texts)\n",
    "num_texts = num_train_texts + num_test_texts\n",
    "# texts = load_dataset('wiki40b', 'en')\n",
    "# print(f\"num: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tf with cpu\n",
      "UniSim is not storing a copy of the index data to save memory\n",
      "If you want to store it use store_data=True\n",
      "[Embedder]\n",
      "|-batch_size:4096\n",
      "[Indexer]\n",
      "|-is_exact:False\n",
      "|-use_tf_knn:False\n",
      "|-store index data:False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BATCH_SIZE = 4096\n",
    "STORE_DATA = False\n",
    "TFKNN = False\n",
    "APPROX = True\n",
    "\n",
    "os.environ['BACKEND'] = 'tf'  # or tf or comment for auto\n",
    "from unisim import ExactUniSim, ApproxUniSim\n",
    "if APPROX:\n",
    "\n",
    "    usim = ApproxUniSim(store_data=STORE_DATA,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    use_tf_knn=TFKNN)\n",
    "else:\n",
    "    usim = ExactUniSim(store_data=STORE_DATA,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    use_tf_knn=TFKNN)\n",
    "\n",
    "\n",
    "# usim = ApproxUniSim(store_data=False)\n",
    "usim.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elieb/git/unisim/.env/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.82embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 20/20 [00:00<00:00, 81.53embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 20/20 [00:00<00:00, 267.07embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "usim.text.embed('warm-up')\n",
    "usim.text.reset_index()\n",
    "usim.text.batch_index(test_texts[:20])\n",
    "dups = usim.text.batch_search(test_texts[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings:  96%|█████████▌| 8192/8530 [00:53<00:02, 160.51embeddings/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 43 calls to <function predict at 0x29e54fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 8530/8530 [00:54<00:00, 155.86embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 1066/1066 [00:04<00:00, 239.74embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 8530/8530 [00:50<00:00, 169.27embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 1066/1066 [00:04<00:00, 239.65embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "usim.text.reset_index()\n",
    "\n",
    "cnts = PerfCounters()\n",
    "cnts.start('total')\n",
    "\n",
    "cnts.start('indexing-train')\n",
    "usim.text.batch_index(train_texts)\n",
    "cnts.stop('indexing-train')\n",
    "\n",
    "cnts.start('indexing-test')\n",
    "usim.text.batch_index(test_texts)\n",
    "cnts.stop('indexing-test')\n",
    "\n",
    "cnts.start('search-train')\n",
    "train_dups = usim.text.batch_search(train_texts)\n",
    "cnts.stop('search-train')\n",
    "\n",
    "cnts.start('search-test')\n",
    "train_dups = usim.text.batch_search(test_texts)\n",
    "cnts.stop('search-test')\n",
    "\n",
    "cnts.stop('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total', 121.98661589622498]\n",
      "['indexing-train', 58.14421033859253]\n",
      "['search-train', 53.8358268737793]\n",
      "['search-test', 5.1059370040893555]\n",
      "['indexing-test', 4.900509834289551]\n",
      "timing\n",
      "total: 122 sec - 78.66  ex/s\n",
      "embedding_time: fixme\n",
      "indexing:fixme\n"
     ]
    }
   ],
   "source": [
    "# timings\n",
    "counters = {}\n",
    "for c in cnts.get_all()['Timing counters']:\n",
    "    print(c)\n",
    "    counters[c[0]] = c[1]\n",
    "\n",
    "print(\"timing\")\n",
    "print(f\"total: {round(counters['total'])} sec - {round(num_texts / counters['total'], 2)}  ex/s\")\n",
    "print(f\"embedding_time: fixme\")\n",
    "print(f\"indexing:fixme\")\n",
    "\n",
    "print(\"Train\")\n",
    "neardup_train_ratio = train_dups.total_global_matches / num_train_texts\n",
    "neardup_test_ratio = test_dups.total_global_matches / num\n",
    "\n",
    "# iqps = num_train_texts / cnts.get('indexing')\n",
    "# sqps = num_test_texts / cnts.get('search')\n",
    "# print(f'indexing {round(iqps)} qps')\n",
    "# print(f'search {round(sqps)} qps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0: \"lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\"\n",
      "  idx  is_global      global_sim  is_partial      partial_sim  content\n",
      "-----  -----------  ------------  ------------  -------------  ------------------------------\n",
      " 8530  True                 1     True                   1     lovingly photographed in the m\n",
      " 2173  False                0.66  False                  0.66  it's refreshing to see a movie\n",
      " 2062  False                0.65  False                  0.65  one hour photo may seem disapp\n",
      " 7069  False                0.65  False                  0.65  succumbs to the same kind of m\n",
      " 2601  False                0.65  False                  0.65  the sweetest thing , a romanti\n"
     ]
    }
   ],
   "source": [
    "# set True to store data to show the cotent\n",
    "for d in dups:\n",
    "    if d.num_global_matches:\n",
    "        usim.viz.result(d)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11924 sec, 3.3h\n"
     ]
    }
   ],
   "source": [
    "wiki_time = (3_000_000 / iqps)\n",
    "wiki_hour = wiki_time / 3600\n",
    "print(f\"{round(wiki_time)} sec, {round(wiki_hour, 1)}h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 8530/8530 [00:44<00:00, 189.77embeddings/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=[Timing counters]=-\n",
      "+-----------+------------+\n",
      "| name      |      value |\n",
      "|-----------+------------|\n",
      "| total     | 47.9073    |\n",
      "| predict   | 44.9494    |\n",
      "| binarizer |  2.91629   |\n",
      "| averaging |  0.0415931 |\n",
      "+-----------+------------+\n",
      "\n",
      "\n",
      "-=[Timing counters]=-\n",
      "+----------------------------+--------------+\n",
      "| name                       |        value |\n",
      "|----------------------------+--------------|\n",
      "| total                      | 48.5263      |\n",
      "| batch_embed                | 47.9169      |\n",
      "| batch_index                |  0.603534    |\n",
      "| flatten_partial_embeddings |  0.00552797  |\n",
      "| compute_global_idxs        |  0.000332117 |\n",
      "+----------------------------+--------------+\n",
      "\n",
      "\n",
      "1066\n"
     ]
    }
   ],
   "source": [
    "usim.text.reset_index()\n",
    "g = usim.text.batch_index(train_texts, verbose=1)\n",
    "print(num_test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > (num_dup - len(dups)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexing\n",
    "\n",
    "## binarizer\n",
    "- fused operation  0.31305\n",
    "- baseline         0.325764  \n",
    "\n",
    "# searching\n",
    "## TF compile\n",
    "-=[Timing counters]=-\n",
    "+----------+---------+\n",
    "| name     |   value |\n",
    "|----------+---------|\n",
    "| total    | 5.63792 |\n",
    "| indexing | 3.94475 |\n",
    "| search   | 1.69313 |\n",
    "+----------+---------+\n",
    "indexing 254 qps\n",
    "search 295 qps  vs 236qps\n",
    "\n",
    "\n",
    "# not useful \n",
    "- store data=False not useful on 1000 example\n",
    "\n",
    "\n",
    "# baseline\n",
    "\n",
    "| name     |   value |\n",
    "|----------+---------|\n",
    "| total    | 6.36012 |\n",
    "| indexing | 4.37516 |\n",
    "| search   | 1.9849  |\n",
    "\n",
    "indexing 223 qps\n",
    "search 236 qps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
