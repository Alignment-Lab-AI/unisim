{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elieb/git/unisim/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from datasets import load_dataset\n",
    "from perfcounters import PerfCounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "test = load_dataset(\"rotten_tomatoes\", split=\"test\")\n",
    "train_texts = [t['text'] for t in train]\n",
    "test_texts = [t['text'] for t in test]\n",
    "\n",
    "# texts = load_dataset('wiki40b', 'en')\n",
    "# print(f\"num: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tf with cpu\n",
      "UniSim is storing a copy of the indexed data\n",
      "if you are using large data corpus consider disable this behavior using store_data=False\n",
      "[Embedder]\n",
      "|-batch_size:1024\n",
      "[Indexer]\n",
      "|-is_exact:True\n",
      "|-use_tf_knn:True\n",
      "|-store index data:True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['BACKEND'] = 'tf'  # or tf or comment for auto\n",
    "from unisim import ExactUniSim, ApproxUniSim\n",
    "usim = ExactUniSim(store_data=True,\n",
    "                   batch_size=1024,\n",
    "                   use_tf_knn=True)\n",
    "# usim = ApproxUniSim(store_data=False)\n",
    "usim.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elieb/git/unisim/.env/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 2/2 [00:00<00:00, 10.80embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 20/20 [00:00<00:00, 110.75embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "v = usim.text.batch_embed(['lala', 'lali'])\n",
    "idx = usim.text.batch_index(test_texts[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ges (20, 256)\n",
    "bpes (1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.11embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 20/20 [00:00<00:00, 290.50embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 20/20 [00:00<00:00, 283.10embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "usim.text.embed('warm-up')\n",
    "usim.text.reset_index()\n",
    "usim.text.batch_index(test_texts[:20])\n",
    "dups = usim.text.batch_search(test_texts[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "index_texts = train_texts + test_texts[:100]\n",
    "query_texts = test_texts[:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 8630/8630 [00:31<00:00, 273.82embeddings/s]\n",
      "Computing partial embeddings: 100%|██████████| 500/500 [00:01<00:00, 266.21embeddings/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=[Timing counters]=-\n",
      "+----------+----------+\n",
      "| name     |    value |\n",
      "|----------+----------|\n",
      "| total    | 36.3945  |\n",
      "| indexing | 34.3018  |\n",
      "| search   |  2.09272 |\n",
      "+----------+----------+\n",
      "\n",
      "\n",
      "indexing 252 qps\n",
      "search 239 qps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usim.text.reset_index()\n",
    "\n",
    "cnts = PerfCounters()\n",
    "cnts.start('total')\n",
    "\n",
    "cnts.start('indexing')\n",
    "usim.text.batch_index(index_texts)\n",
    "cnts.stop('indexing')\n",
    "\n",
    "cnts.start('search')\n",
    "dups = usim.text.batch_search(query_texts)\n",
    "cnts.stop('search')\n",
    "cnts.stop('total')\n",
    "\n",
    "\n",
    "cnts.report()\n",
    "iqps = len(index_texts) / cnts.get('indexing')\n",
    "sqps = len(query_texts) / cnts.get('search')\n",
    "print(f'indexing {round(iqps)} qps')\n",
    "print(f'search {round(sqps)} qps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0: \"lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\"\n",
      "  idx  is_global      global_sim  is_partial      partial_sim  content\n",
      "-----  -----------  ------------  ------------  -------------  ------------------------------\n",
      " 8530  True                 1     True                   1     lovingly photographed in the m\n",
      " 2173  False                0.66  False                  0.66  it's refreshing to see a movie\n",
      " 2062  False                0.65  False                  0.65  one hour photo may seem disapp\n",
      " 7069  False                0.65  False                  0.65  succumbs to the same kind of m\n",
      " 2601  False                0.65  False                  0.65  the sweetest thing , a romanti\n"
     ]
    }
   ],
   "source": [
    "# set True to store data to show the cotent\n",
    "for d in dups:\n",
    "    if d.num_global_matches:\n",
    "        usim.viz.result(d)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11924 sec, 3.3h\n"
     ]
    }
   ],
   "source": [
    "wiki_time = (3_000_000 / iqps)\n",
    "wiki_hour = wiki_time / 3600\n",
    "print(f\"{round(wiki_time)} sec, {round(wiki_hour, 1)}h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partial embeddings: 100%|██████████| 500/500 [00:01<00:00, 284.80embeddings/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=[Timing counters]=-\n",
      "+-----------+------------+\n",
      "| name      |      value |\n",
      "|-----------+------------|\n",
      "| total     | 1.91406    |\n",
      "| predict   | 1.75639    |\n",
      "| binarizer | 0.154915   |\n",
      "| averaging | 0.00274587 |\n",
      "+-----------+------------+\n",
      "\n",
      "\n",
      "-=[Timing counters]=-\n",
      "+----------------------------+-------------+\n",
      "| name                       |       value |\n",
      "|----------------------------+-------------|\n",
      "| total                      | 1.91514     |\n",
      "| batch_embed                | 1.91473     |\n",
      "| flatten_partial_embeddings | 0.000333071 |\n",
      "| batch_index                | 5.72205e-05 |\n",
      "| compute_global_idxs        | 1.4782e-05  |\n",
      "| store_data                 | 2.14577e-06 |\n",
      "+----------------------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usim.text.reset_index()\n",
    "g = usim.text.batch_index(query_texts, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexing\n",
    "\n",
    "## binarizer\n",
    "- fused operation  0.31305\n",
    "- baseline         0.325764  \n",
    "\n",
    "# searching\n",
    "## TF compile\n",
    "-=[Timing counters]=-\n",
    "+----------+---------+\n",
    "| name     |   value |\n",
    "|----------+---------|\n",
    "| total    | 5.63792 |\n",
    "| indexing | 3.94475 |\n",
    "| search   | 1.69313 |\n",
    "+----------+---------+\n",
    "indexing 254 qps\n",
    "search 295 qps  vs 236qps\n",
    "\n",
    "\n",
    "# not useful \n",
    "- store data=False not useful on 1000 example\n",
    "\n",
    "\n",
    "# baseline\n",
    "\n",
    "| name     |   value |\n",
    "|----------+---------|\n",
    "| total    | 6.36012 |\n",
    "| indexing | 4.37516 |\n",
    "| search   | 1.9849  |\n",
    "\n",
    "indexing 223 qps\n",
    "search 236 qps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
