{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datasets import load_dataset\n",
    "from perfcounters import PerfCounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "test = load_dataset(\"rotten_tomatoes\", split=\"test\")\n",
    "train_texts = [t['text'] for t in train]\n",
    "test_texts = [t['text'] for t in test]\n",
    "num_train_texts = len(train_texts)\n",
    "num_test_texts = len(test_texts)\n",
    "num_texts = num_train_texts + num_test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniSim is storing a copy of the indexed data\n",
      "If you are using large data corpus, consider disabling this behavior using store_data=False\n",
      "Accelerator is not available, using cpu instead\n",
      "[Embedder]\n",
      "|-batch_size: 256\n",
      "|-model_id: text/retsim/v1\n",
      "|-embedding_size: 256\n",
      "[Indexer]\n",
      "|-index_type: approx\n",
      "|-use_accelerator: False\n",
      "|-store index data: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BATCH_SIZE = 256\n",
    "STORE_DATA = False\n",
    "APPROX = True\n",
    "\n",
    "os.environ['BACKEND'] = 'onnx'  # or tf or comment for auto\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "from unisim import TextSim\n",
    "if APPROX:\n",
    "    tsim = TextSim(index_type=\"approx\", batch_size=BATCH_SIZE)\n",
    "else:\n",
    "    tsim = TextSim(index_type=\"exact\", batch_size=BATCH_SIZE)\n",
    "\n",
    "tsim.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-[Results Statistics]-\n",
      "Number of Results: 20\n",
      "Total Global Matches: 20\n",
      "Total Partial Matches: 20\n"
     ]
    }
   ],
   "source": [
    "tsim.embed(['warm-up'])\n",
    "tsim.reset_index()\n",
    "tsim.index(test_texts[:20])\n",
    "dups = tsim.search(test_texts[:20])\n",
    "print(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsim.reset_index()\n",
    "\n",
    "cnts = PerfCounters()\n",
    "cnts.start('total')\n",
    "\n",
    "cnts.start('indexing-train')\n",
    "tsim.index(train_texts)\n",
    "cnts.stop('indexing-train')\n",
    "\n",
    "cnts.start('indexing-test')\n",
    "tsim.index(test_texts)\n",
    "cnts.stop('indexing-test')\n",
    "\n",
    "cnts.start('search-train')\n",
    "train_dups = tsim.search(train_texts)\n",
    "cnts.stop('search-train')\n",
    "\n",
    "cnts.start('search-test')\n",
    "test_dups = tsim.search(test_texts)\n",
    "cnts.stop('search-test')\n",
    "\n",
    "cnts.stop('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=[Timing counters]=-\n",
      "+----------------+----------+\n",
      "| name           |    value |\n",
      "|----------------+----------|\n",
      "| total          | 39.5803  |\n",
      "| indexing-train | 18.0286  |\n",
      "| search-train   | 17.3134  |\n",
      "| search-test    |  2.12564 |\n",
      "| indexing-test  |  2.11229 |\n",
      "+----------------+----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnts.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total', 40.264972448349]\n",
      "['indexing-train', 18.601977348327637]\n",
      "['search-train', 17.315526962280273]\n",
      "['search-test', 2.1855432987213135]\n",
      "['indexing-test', 2.1615777015686035]\n",
      "timing\n",
      "total: 40 sec - 238.32  ex/s\n",
      "embedding_time: fixme\n",
      "indexing:fixme\n",
      "Train\n",
      "indexing 459 qps\n",
      "search 488 qps\n"
     ]
    }
   ],
   "source": [
    "# timings\n",
    "counters = {}\n",
    "for c in cnts.get_all()['Timing counters']:\n",
    "    print(c)\n",
    "    counters[c[0]] = c[1]\n",
    "\n",
    "print(\"timing\")\n",
    "print(f\"total: {round(counters['total'])} sec - {round(num_texts / counters['total'], 2)}  ex/s\")\n",
    "print(f\"embedding_time: fixme\")\n",
    "print(f\"indexing:fixme\")\n",
    "\n",
    "print(\"Train\")\n",
    "neardup_train_ratio = train_dups.total_global_matches / num_train_texts\n",
    "\n",
    "iqps = num_train_texts / cnts.get('indexing-train')\n",
    "sqps = num_test_texts / cnts.get('search-test')\n",
    "print(f'indexing {round(iqps)} qps')\n",
    "print(f'search {round(sqps)} qps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5280528664588928"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = train_texts[2062]\n",
    "t2 = \"lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\"\n",
    "tsim.similarity(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# [0.1, 0.3, 0.4,0.5]/np.linalg.norm([0.1, 0.3, 0.4,0.5],axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.math.l2_normalize([0.1, 0.3, 0.4,0.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.52804935]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"/workspace/RetSim/models/retsim_infinity/retsim_infinite_model_v1\")\n",
    "e1 = model.predict(tf.constant([t1]))\n",
    "e2 = model.predict(tf.constant([t2]))\n",
    "\n",
    "# with tf.device()\n",
    "tf.matmul(e1[\"global_embedding\"], e2[\"global_embedding\"], transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0: \"lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\"\n",
      "  idx  is_global    global_sim    is_partial    partial_sim    content\n",
      "-----  -----------  ------------  ------------  -------------  --------------------------------\n",
      " 8530  True         1.0           True          1.0            lovingly photographed in the man\n",
      " 8979  False        0.57          False         0.57           waydowntown manages to nail the\n",
      " 8960  False        0.56          False         0.56           manages to delight without much\n",
      " 8209  False        0.54          False                        unfortunately , one hour photo l\n",
      " 3510  False        0.54          False                        if divine secrets of the ya-ya s\n",
      "  909  False                      False         0.56           culkin , who's in virtually ever\n",
      " 3951  False                      False         0.55           baran is shockingly devoid of yo\n"
     ]
    }
   ],
   "source": [
    "# set True to store data to show the cotent\n",
    "for d in test_dups.results[0:]:\n",
    "    if d.num_global_matches:\n",
    "        tsim.visualize(d)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6542 sec, 1.8h\n"
     ]
    }
   ],
   "source": [
    "wiki_time = (3_000_000 / iqps)\n",
    "wiki_hour = wiki_time / 3600\n",
    "print(f\"{round(wiki_time)} sec, {round(wiki_hour, 1)}h\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
